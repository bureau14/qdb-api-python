from __future__ import annotations

import datetime

import numpy as np

from ._batch_column import BatchColumnInfo
from ._batch_inserter import TimeSeriesBatch
from ._blob import Blob
from ._continuous import QueryContinuous
from ._double import Double
from ._integer import Integer
from ._node import Node
from ._options import Options
from ._perf import Perf
from ._properties import Properties
from ._reader import Reader
from ._string import String
from ._table import Table
from ._tag import Tag
from ._timestamp import Timestamp
from ._writer import Writer

class Cluster:
    """
    Represents a connection to the QuasarDB cluster.
    """

    def __enter__(self) -> Cluster: ...
    def __exit__(self, exc_type: object, exc_value: object, exc_tb: object) -> None: ...
    def __init__(
        self,
        uri: str,
        user_name: str = "",
        user_private_key: str = "",
        cluster_public_key: str = "",
        user_security_file: str = "",
        cluster_public_key_file: str = "",
        timeout: datetime.timedelta = datetime.timedelta(minutes=1),
        do_version_check: bool = False,
        enable_encryption: bool = False,
        compression_mode: Options.Compression = ...,  # balanced
        client_max_parallelism: int = 0,
    ) -> None: ...
    def blob(self, alias: str) -> Blob: ...
    def close(self) -> None: ...
    def compact_abort(self) -> None: ...
    def compact_full(self) -> None: ...
    def compact_progress(self) -> int: ...
    def double(self, alias: str) -> Double: ...
    def endpoints(self) -> list[str]: ...
    def find(self, query: str) -> list[str]: ...
    def get_memory_info(self) -> str: ...
    def inserter(self, column_info_list: list[BatchColumnInfo]) -> TimeSeriesBatch: ...
    def integer(self, alias: str) -> Integer: ...
    def is_open(self) -> bool: ...
    def node(self, uri: str) -> Node: ...
    def node_config(self, uri: str) -> dict[str, object]: ...
    def node_status(self, uri: str) -> dict[str, object]: ...
    def node_topology(self, uri: str) -> dict[str, object]: ...
    def options(self) -> Options: ...
    def perf(self) -> Perf: ...
    def pinned_writer(self) -> Writer: ...
    def prefix_count(self, prefix: str) -> int: ...
    def prefix_get(self, prefix: str, max_count: int) -> list[str]: ...
    def properties(self) -> Properties: ...
    def purge_all(self, timeout: datetime.timedelta) -> None: ...
    def purge_cache(self, timeout: datetime.timedelta) -> None: ...
    def query(
        self, query: str, blobs: bool | list[str] = False
    ) -> list[dict[str, object]]: ...
    def query_continuous_full(
        self, query: str, pace: datetime.timedelta, blobs: bool | list[str] = False
    ) -> QueryContinuous: ...
    def query_continuous_new_values(
        self, query: str, pace: datetime.timedelta, blobs: bool | list[str] = False
    ) -> QueryContinuous: ...
    def query_numpy(self, query: str) -> list[tuple[str, np.ma.MaskedArray]]: ...
    def reader(
        self,
        table_names: list[str],
        column_names: list[str] = [],
        batch_size: int = 0,
        ranges: list[tuple] = [],
    ) -> Reader: ...
    def string(self, alias: str) -> String: ...
    def suffix_count(self, suffix: str) -> int: ...
    def suffix_get(self, suffix: str, max_count: int) -> list[str]: ...
    def table(self, alias: str) -> Table: ...
    def tag(self, alias: str) -> Tag: ...
    def tidy_memory(self) -> None: ...
    def timestamp(self, alias: str) -> Timestamp: ...
    def trim_all(
        self, pause: datetime.timedelta, timeout: datetime.timedelta
    ) -> None: ...
    def ts(self, alias: str) -> Table: ...
    def ts_batch(self, column_info_list: list[BatchColumnInfo]) -> TimeSeriesBatch: ...
    def uri(self) -> str: ...
    def wait_for_compaction(self) -> None: ...
    def writer(self) -> Writer: ...
